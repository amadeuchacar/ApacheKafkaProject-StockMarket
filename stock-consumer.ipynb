{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8f9e4b",
   "metadata": {},
   "source": [
    "## APACHE KAFKA PROJECT 01 - CONSUMER\n",
    "Creating the consumer to send data from Apache Kafka to a AWS S3 Bucket.\n",
    "The data is a real time simulation with a stock market file (CSV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a16093",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d549e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kafka import KafkaConsumer\n",
    "from time import sleep\n",
    "from json import dumps, loads\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7581c",
   "metadata": {},
   "source": [
    "#### Loading the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "bootstrap_servers = os.environ.get('BOOTSTRAP_SERVERS')\n",
    "topic_name = os.environ.get('TOPIC_NAME')\n",
    "aws_access_key = os.environ.get('AWS_ACCESS_KEY')\n",
    "aws_secret_key = os.environ.get('AWS_SECRET_KEY')\n",
    "s3_region = os.environ.get('S3_REGION')\n",
    "bucket_name = os.environ.get('BUCKET_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57f4b9",
   "metadata": {},
   "source": [
    "#### Creating the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5edeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(topic_name,\n",
    "                         bootstrap_servers = bootstrap_servers,\n",
    "                         value_deserializer = lambda x: loads(x.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a094d7b",
   "metadata": {},
   "source": [
    "#### Creating the S3 object to upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3807e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    service_name = 's3',\n",
    "    region_name = s3_region,\n",
    "    aws_access_key_id = aws_access_key,\n",
    "    aws_secret_access_key = aws_secret_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116035a7",
   "metadata": {},
   "source": [
    "#### Sending the data from Apache Kafka to AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, i in enumerate(consumer):\n",
    "    json_file = json.dumps(i.value, default=str)\n",
    "    s3.put_object(Body=json_file, Bucket=bucket_name, Key='stock_market_{}.json'.format(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
